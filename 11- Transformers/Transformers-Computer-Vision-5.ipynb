{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPa+C+LtJ0Ktbe7KXKFiUUt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Mask Generation**"],"metadata":{"id":"FmRxmAsJyME2"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"1oR81RquyGL1","executionInfo":{"status":"ok","timestamp":1727933988668,"user_tz":-180,"elapsed":10020,"user":{"displayName":"Alperen Erdoğan","userId":"17997311624432346920"}}},"outputs":[],"source":["!pip install -q transformers"]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","checkpoint = \"facebook/sam-vit-base\"\n","mask_generator = pipeline(model=checkpoint, task=\"mask-generation\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v49WP_1hyR_1","executionInfo":{"status":"ok","timestamp":1727934200315,"user_tz":-180,"elapsed":19174,"user":{"displayName":"Alperen Erdoğan","userId":"17997311624432346920"}},"outputId":"cd14cc4c-2286-4ed9-ad1d-c1836396608f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","import requests\n","\n","img_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"\n","image = Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\")"],"metadata":{"id":"7sY9l3fFySCC","executionInfo":{"status":"ok","timestamp":1727934177718,"user_tz":-180,"elapsed":541,"user":{"displayName":"Alperen Erdoğan","userId":"17997311624432346920"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["masks = mask_generator(image, points_per_batch=128, pred_iou_thresh=0.88)"],"metadata":{"id":"owJ_mhWCySEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.imshow(image, cmap='gray')\n","\n","for i, mask in enumerate(masks[\"masks\"]):\n","    plt.imshow(mask, cmap='viridis', alpha=0.1, vmin=0, vmax=1)\n","\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"FHBRRU_7ySGj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import SamModel, SamProcessor\n","import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = SamModel.from_pretrained(\"facebook/sam-vit-base\").to(device)\n","processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"],"metadata":{"id":"jYc-7HCbySI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_points = [[[2592, 1728]]]\n","\n","inputs = processor(image, input_points=input_points, return_tensors=\"pt\").to(device)\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","masks = processor.image_processor.post_process_masks(outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu())"],"metadata":{"id":"3mLkFe46ySKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n","\n","axes[0].imshow(image)\n","axes[0].set_title('Original Image')\n","mask_list = [masks[0][0][0].numpy(), masks[0][0][1].numpy(), masks[0][0][2].numpy()]\n","\n","for i, mask in enumerate(mask_list, start=1):\n","    overlayed_image = np.array(image).copy()\n","\n","    overlayed_image[:,:,0] = np.where(mask == 1, 255, overlayed_image[:,:,0])\n","    overlayed_image[:,:,1] = np.where(mask == 1, 0, overlayed_image[:,:,1])\n","    overlayed_image[:,:,2] = np.where(mask == 1, 0, overlayed_image[:,:,2])\n","\n","    axes[i].imshow(overlayed_image)\n","    axes[i].set_title(f'Mask {i}')\n","for ax in axes:\n","    ax.axis('off')\n","\n","plt.show()"],"metadata":{"id":"GUGz9YQtybf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box = [2350, 1600, 2850, 2100]\n","\n","inputs = processor(\n","        image,\n","        input_boxes=[[[box]]],\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","mask = processor.image_processor.post_process_masks(\n","    outputs.pred_masks.cpu(),\n","    inputs[\"original_sizes\"].cpu(),\n","    inputs[\"reshaped_input_sizes\"].cpu()\n",")[0][0][0].numpy()"],"metadata":{"id":"G8veZF-oybh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.patches as patches\n","\n","fig, ax = plt.subplots()\n","ax.imshow(image)\n","\n","rectangle = patches.Rectangle((2350, 1600), 500, 500, linewidth=2, edgecolor='r', facecolor='none')\n","ax.add_patch(rectangle)\n","ax.axis(\"off\")\n","plt.show()"],"metadata":{"id":"qT8Eb7eHyblR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots()\n","ax.imshow(image)\n","ax.imshow(mask, cmap='viridis', alpha=0.4)\n","\n","ax.axis(\"off\")\n","plt.show()"],"metadata":{"id":"lpu7wRwAymDZ"},"execution_count":null,"outputs":[]}]}